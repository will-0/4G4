{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NN for Iris.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "-GPLENySjriw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "anT-jJ1cj4K5",
        "colab_type": "text"
      },
      "source": [
        "# ** Neural Network for Iris Dataset **"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w2tkSsPlkBgX",
        "colab_type": "text"
      },
      "source": [
        "NN for the Iris dataset using keras and backpropagation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gxg1ynUvkd8Z",
        "colab_type": "code",
        "outputId": "2b44999e-6dc3-4aa9-a24a-f3138da36914",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        }
      },
      "source": [
        "%matplotlib inline\n",
        "from matplotlib import pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "!pip3 install git+https://github.com/tensorflow/docs\n",
        "import tensorflow_docs as tfdocs\n",
        "import tensorflow_docs.plots\n",
        "import tensorflow_docs.modeling\n",
        "\n",
        "print(tf.__version__)\n",
        "\n",
        "from IPython.display import SVG\n",
        "from keras.utils import model_to_dot\n",
        "import pydot\n",
        "\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/pip3\", line 5, in <module>\n",
            "    from pip._internal.main import main\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pip/_internal/main.py\", line 13, in <module>\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pip/_internal/cli/autocompletion.py\", line 11, in <module>\n",
            "    from pip._internal.cli.main_parser import create_main_parser\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pip/_internal/cli/main_parser.py\", line 7, in <module>\n",
            "    from pip._internal.cli import cmdoptions\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pip/_internal/cli/cmdoptions.py\", line 24, in <module>\n",
            "    from pip._internal.exceptions import CommandError\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pip/_internal/exceptions.py\", line 10, in <module>\n",
            "    from pip._vendor.six import iteritems\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pip/_vendor/__init__.py\", line 10, in <module>\n",
            "    import glob\n",
            "  File \"<frozen importlib._bootstrap>\", line 971, in _find_and_load\n",
            "  File \"<frozen importlib._bootstrap>\", line 955, in _find_and_load_unlocked\n",
            "  File \"<frozen importlib._bootstrap>\", line 665, in _load_unlocked\n",
            "  File \"<frozen importlib._bootstrap_external>\", line 674, in exec_module\n",
            "  File \"<frozen importlib._bootstrap_external>\", line 771, in get_code\n",
            "  File \"<frozen importlib._bootstrap_external>\", line 470, in _validate_bytecode_header\n",
            "  File \"<frozen importlib._bootstrap_external>\", line 54, in _r_long\n",
            "KeyboardInterrupt\n",
            "1.15.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LyAVoO0ZkmKL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Weights and biases to track the hyperparameters\n",
        "# import wandb\n",
        "# wandb.init(project=\"nn-testing\")\n",
        "# from wandb.keras import WandbCallback\n",
        "# wandb.init(config={\"hyper\": \"parameter\"})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QcyChPPikpu3",
        "colab_type": "code",
        "outputId": "0af0a79f-f6a2-475f-d580-0f43e9342cfd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "iris = load_iris()\n",
        "X = iris['data'] # array of samples 4 dimensions each describing a feature\n",
        "y = iris['target'] # array of labels (0, 1, 2)\n",
        "names = iris['target_names'] # array of labels (0, 1, 2)\n",
        "feature_names = iris['feature_names'] # ['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)']\n",
        "\n",
        "# One hot encoding\n",
        "enc = OneHotEncoder()\n",
        "Y = enc.fit_transform(y[:, np.newaxis]).toarray() # Y is output of 3 dimensions now, one hot encoding\n",
        "\n",
        "# Scale data to have mean 0 and variance 1 \n",
        "# which is importance for convergence of the neural network\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Split the data set into training and testing\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(\n",
        "X_scaled, Y, test_size=0.5, random_state=2)\n",
        "\n",
        "n_features = X.shape[1]\n",
        "n_classes = Y.shape[1]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}